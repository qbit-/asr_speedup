{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_puOQgbO9Lho"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.python.platform import gfile\n",
    "from tensorflow.python.framework import tensor_util\n",
    "import tensorflow.contrib.graph_editor as ge\n",
    "import t3f\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(tf.__version__ == '1.15.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "PyKnr8gEB-P-",
    "outputId": "8c8bd80c-15f6-4278-9bfd-cc291436a877"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: deepspeech in /usr/local/lib/python3.7/site-packages (0.6.1)\r\n",
      "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/site-packages (from deepspeech) (1.18.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip3 install deepspeech\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "3L7wBLvWr3ta",
    "outputId": "0d972405-821f-4901-bfe3-920ebfbcebf8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   620  100   620    0     0   1172      0 --:--:-- --:--:-- --:--:--  1172\n",
      "100 1172M  100 1172M    0     0  4629k      0  0:04:19  0:04:19 --:--:-- 5597k      0  0:03:38  0:00:12  0:03:26 6456k8k      0  0:03:37  0:00:20  0:03:17 5362k1  0:03:31 3817k27k      0  0:04:13  0:01:02  0:03:11 4106k      0  0:04:07  0:01:14  0:02:53 5679k     0  4488k      0  0:04:27  0:01:53  0:02:34 5082k8k      0  0:04:25  0:02:03  0:02:22 5131k  4628k      0  0:04:19  0:03:22  0:00:57 4556k19  0:03:24  0:00:55 4280k\n",
      "x deepspeech-0.6.1-models/\n",
      "x deepspeech-0.6.1-models/lm.binary\n",
      "x deepspeech-0.6.1-models/output_graph.pbmm\n",
      "x deepspeech-0.6.1-models/output_graph.pb\n",
      "x deepspeech-0.6.1-models/trie\n",
      "x deepspeech-0.6.1-models/output_graph.tflite\n"
     ]
    }
   ],
   "source": [
    "!curl -LO https://github.com/mozilla/DeepSpeech/releases/download/v0.6.1/deepspeech-0.6.1-models.tar.gz\n",
    "!tar xvf deepspeech-0.6.1-models.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "N1kQPWiXr_lV",
    "outputId": "18e3e7e5-2432-4395-eea7-b418fd0ada39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   608  100   608    0     0   1304      0 --:--:-- --:--:-- --:--:--  1304\n",
      "100  192k  100  192k    0     0   114k      0  0:00:01  0:00:01 --:--:--     0 --:--:--  223k\n",
      "x audio/\n",
      "x audio/2830-3980-0043.wav\n",
      "x audio/Attribution.txt\n",
      "x audio/4507-16021-0012.wav\n",
      "x audio/8455-210777-0068.wav\n",
      "x audio/License.txt\n"
     ]
    }
   ],
   "source": [
    "!curl -LO https://github.com/mozilla/DeepSpeech/releases/download/v0.6.1/audio-0.6.1.tar.gz\n",
    "!tar xvf audio-0.6.1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 360
    },
    "colab_type": "code",
    "id": "Rmryh0XKsNTg",
    "outputId": "56fa860c-dfbe-48c8-85e7-cc052790a683"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from file deepspeech-0.6.1-models/output_graph.pb\n",
      "TensorFlow: v1.14.0-21-ge77504ac6b\n",
      "DeepSpeech: v0.6.1-0-g3df20fe\n",
      "Warning: reading entire model file into memory. Transform model file into an mmapped graph to reduce heap usage.\n",
      "2020-03-13 11:17:46.179777: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "Loaded model in 1.6s.\n",
      "Running inference.\n",
      "experience proofsless\n",
      "Inference took 10.170s for 1.975s audio file.\n"
     ]
    }
   ],
   "source": [
    "!deepspeech --model deepspeech-0.6.1-models/output_graph.pb --audio audio/2830-3980-0043.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EYlEajL6xR9U"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wcP9OFTMyT6w"
   },
   "source": [
    "## Weight extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U96SaM18svMJ"
   },
   "outputs": [],
   "source": [
    "def load_deepspeech_graph(graph_path):\n",
    "#GRAPH_PB_PATH = '/content/deepspeech-0.6.1-models/output_graph.pb'\n",
    "  gr = tf.Graph()\n",
    "  wts = {}\n",
    "  with tf.Session(graph=gr) as sess:\n",
    "    print(\"load graph\")\n",
    "    with gfile.FastGFile(graph_path,'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "    graph_def.ParseFromString(f.read())\n",
    "    sess.graph.as_default()\n",
    "    tf.import_graph_def(graph_def, name='',)\n",
    "    graph_nodes=[n for n in graph_def.node]\n",
    "    names = []\n",
    "    for t in graph_nodes:\n",
    "        names.append(t.name)\n",
    "    print(names)\n",
    "    for n in graph_nodes:\n",
    "        if n.op=='Const':\n",
    "          wts[n.name] = tensor_util.MakeNdarray(n.attr[\"value\"].tensor)\n",
    "  return wts, gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N09HK440xUYO"
   },
   "outputs": [],
   "source": [
    "def make_t3f_subgraph(graph,input_shape,W,bias):\n",
    "  model = tf.keras.Sequential()\n",
    "  input_layer = tf.keras.Input((input_shape))\n",
    "  tt_layer = t3f.nn.KerasDense([8,8,4,8],[8,8,8,4],tt_rank=25,activation=\"relu\")\n",
    "  model.add(input_layer)\n",
    "  model.add(tf.keras.layers.Reshape((-1,input_shape)))\n",
    "  model.add(tt_layer)\n",
    "  model.compile(loss=\"mse\", optimizer='rmsprop')\n",
    "  with tf.Session() as sess:\n",
    "    cores = sess.run(W.tt_cores)\n",
    "  params = list(cores)\n",
    "  params.append(bias)\n",
    "  model.set_weights(params)\n",
    "  f_g = freeze_session(K.get_session(),output_names=[out.op.name for out in model.outputs])\n",
    "  #subgraph = tf.Graph()\n",
    "  with tf.Session(graph=graph) as sess:\n",
    "    tf.import_graph_def(f_g, name='',)\n",
    "  return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fphuRoMttnSt"
   },
   "outputs": [],
   "source": [
    "def replace_layer_with_t3f(gr,wts,layer_name):\n",
    "  bias = wts[layer_name+\"/bias\"]\n",
    "  weights = wts[layer_name+\"/weights\"]\n",
    "  tt_weights = t3f.to_tt_matrix(weights,shape=[[8,8,4,8],[8,8,8,4]],max_tt_rank=25)\n",
    "  tt_subgraph = make_t3f_subgraph(gr,2048,tt_weights,bias)\n",
    "  ge.detach(gr.get_operation_by_name(\"MatMul_1\"))\n",
    "  ge.detach(gr.get_operation_by_name(\"input_1\"))\n",
    "  l = ge.make_list_of_op(tt_subgraph)\n",
    "  print(l)\n",
    "\n",
    "  prev_layer_out = gr.get_operation_by_name(\"Minimum\")\n",
    "  tt_layer_in = tt_subgraph.get_operation_by_name(\"reshape/Reshape\")\n",
    "  shape = tt_subgraph.get_operation_by_name(\"reshape/Reshape/shape\")\n",
    "  ge.connect([prev_layer_out,shape],tt_layer_in)\n",
    "  \n",
    "  print(l[0])\n",
    "\n",
    "  tt_layer_out = tt_subgraph.get_operation_by_name(\"keras_dense/activation/Relu\")\n",
    "  minimun_y = gr.get_operation_by_name(\"Minimum_1/y\")\n",
    "  next_layer_in = gr.get_operation_by_name(\"Minimum_1\")\n",
    "  ge.connect([tt_layer_out,minimun_y],next_layer_in)\n",
    "\n",
    "  return tt_subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HUKHsU6Dc8qu"
   },
   "outputs": [],
   "source": [
    "def freeze_session(session, keep_var_names=None, output_names=None, clear_devices=True):\n",
    "    \"\"\"\n",
    "    Freezes the state of a session into a pruned computation graph.\n",
    "\n",
    "    Creates a new computation graph where variable nodes are replaced by\n",
    "    constants taking their current value in the session. The new graph will be\n",
    "    pruned so subgraphs that are not necessary to compute the requested\n",
    "    outputs are removed.\n",
    "    @param session The TensorFlow session to be frozen.\n",
    "    @param keep_var_names A list of variable names that should not be frozen,\n",
    "                          or None to freeze all the variables in the graph.\n",
    "    @param output_names Names of the relevant graph outputs.\n",
    "    @param clear_devices Remove the device directives from the graph for better portability.\n",
    "    @return The frozen graph definition.\n",
    "    \"\"\"\n",
    "    graph = session.graph\n",
    "    with graph.as_default():\n",
    "        freeze_var_names = list(set(v.op.name for v in tf.global_variables()).difference(keep_var_names or []))\n",
    "        output_names = output_names or []\n",
    "        output_names += [v.op.name for v in tf.global_variables()]\n",
    "        input_graph_def = graph.as_graph_def()\n",
    "        if clear_devices:\n",
    "            for node in input_graph_def.node:\n",
    "                node.device = \"\"\n",
    "        frozen_graph = tf.graph_util.convert_variables_to_constants(\n",
    "            session, input_graph_def, output_names, freeze_var_names)\n",
    "        return frozen_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "ExJzdb2_X9zx",
    "outputId": "1f2f6b81-a67f-4f4b-a26e-51086aed19c5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "25ug9pN4YY1j"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load graph\n",
      "['input_samples', 'ExpandDims/dim', 'ExpandDims', 'AudioSpectrogram', 'Mfcc/sample_rate', 'Mfcc', 'Reshape/shape', 'Reshape', 'mfccs', 'input_node', 'input_lengths', 'previous_state_c', 'previous_state_h', 'transpose/perm', 'transpose', 'Reshape_1/shape', 'Reshape_1', 'layer_1/bias', 'layer_1/bias/read', 'layer_1/weights', 'layer_1/weights/read', 'MatMul', 'BiasAdd', 'Relu', 'Minimum/y', 'Minimum', 'layer_2/bias', 'layer_2/bias/read', 'layer_2/weights', 'layer_2/weights/read', 'MatMul_1', 'BiasAdd_1', 'Relu_1', 'Minimum_1/y', 'Minimum_1', 'layer_3/bias', 'layer_3/bias/read', 'layer_3/weights', 'layer_3/weights/read', 'MatMul_2', 'BiasAdd_2', 'Relu_2', 'Minimum_2/y', 'Minimum_2', 'Reshape_2/shape', 'Reshape_2', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel/read', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias/read', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/zeros/shape_as_tensor', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/zeros/Const', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/zeros', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/Const', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/Max', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/Cast', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/BlockLSTM', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/SequenceMask/Const', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/SequenceMask/Const_1', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/SequenceMask/Const_2', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/SequenceMask/Range', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/SequenceMask/ExpandDims/dim', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/SequenceMask/ExpandDims', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/SequenceMask/Cast', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/SequenceMask/Less', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/SequenceMask/Cast_1', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/transpose/perm', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/transpose', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/ExpandDims/dim', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/ExpandDims', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/Tile/multiples', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/Tile', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/mul', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/ExpandDims_1/dim', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/ExpandDims_1', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/concat/axis', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/concat', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/ExpandDims_2/dim', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/ExpandDims_2', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/concat_1/axis', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/concat_1', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/range/start', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/range/limit', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/range/delta', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/range', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/stack', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/GatherNd', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/range_1/start', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/range_1/limit', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/range_1/delta', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/range_1', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/stack_1', 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/GatherNd_1', 'Reshape_3/shape', 'Reshape_3', 'layer_5/bias', 'layer_5/bias/read', 'layer_5/weights', 'layer_5/weights/read', 'MatMul_3', 'BiasAdd_3', 'Relu_3', 'Minimum_3/y', 'Minimum_3', 'layer_6/bias', 'layer_6/bias/read', 'layer_6/weights', 'layer_6/weights/read', 'MatMul_4', 'BiasAdd_4', 'raw_logits/shape', 'raw_logits', 'logits', 'new_state_c', 'new_state_h', 'metadata_version', 'metadata_sample_rate', 'metadata_feature_win_len', 'metadata_feature_win_step', 'metadata_alphabet']\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "wts, gr = load_deepspeech_graph(\"deepspeech-0.6.1-models/output_graph.pb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "colab_type": "code",
    "id": "1aWEEovrKayJ",
    "outputId": "3307bea2-2d46-4ae4-e5be-4be530e2ce06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 5 variables.\n",
      "INFO:tensorflow:Converted 5 variables to const ops.\n",
      "[<tf.Operation 'input_samples' type=Placeholder>, <tf.Operation 'ExpandDims/dim' type=Const>, <tf.Operation 'ExpandDims' type=ExpandDims>, <tf.Operation 'AudioSpectrogram' type=AudioSpectrogram>, <tf.Operation 'Mfcc/sample_rate' type=Const>, <tf.Operation 'Mfcc' type=Mfcc>, <tf.Operation 'Reshape/shape' type=Const>, <tf.Operation 'Reshape' type=Reshape>, <tf.Operation 'mfccs' type=Identity>, <tf.Operation 'input_node' type=Placeholder>, <tf.Operation 'input_lengths' type=Placeholder>, <tf.Operation 'previous_state_c' type=Placeholder>, <tf.Operation 'previous_state_h' type=Placeholder>, <tf.Operation 'transpose/perm' type=Const>, <tf.Operation 'transpose' type=Transpose>, <tf.Operation 'Reshape_1/shape' type=Const>, <tf.Operation 'Reshape_1' type=Reshape>, <tf.Operation 'layer_1/bias' type=Const>, <tf.Operation 'layer_1/bias/read' type=Identity>, <tf.Operation 'layer_1/weights' type=Const>, <tf.Operation 'layer_1/weights/read' type=Identity>, <tf.Operation 'MatMul' type=MatMul>, <tf.Operation 'BiasAdd' type=BiasAdd>, <tf.Operation 'Relu' type=Relu>, <tf.Operation 'Minimum/y' type=Const>, <tf.Operation 'Minimum' type=Minimum>, <tf.Operation 'layer_2/bias' type=Const>, <tf.Operation 'layer_2/bias/read' type=Identity>, <tf.Operation 'layer_2/weights' type=Const>, <tf.Operation 'layer_2/weights/read' type=Identity>, <tf.Operation 'MatMul_1' type=MatMul>, <tf.Operation 'BiasAdd_1' type=BiasAdd>, <tf.Operation 'Relu_1' type=Relu>, <tf.Operation 'Minimum_1/y' type=Const>, <tf.Operation 'Minimum_1' type=Minimum>, <tf.Operation 'layer_3/bias' type=Const>, <tf.Operation 'layer_3/bias/read' type=Identity>, <tf.Operation 'layer_3/weights' type=Const>, <tf.Operation 'layer_3/weights/read' type=Identity>, <tf.Operation 'MatMul_2' type=MatMul>, <tf.Operation 'BiasAdd_2' type=BiasAdd>, <tf.Operation 'Relu_2' type=Relu>, <tf.Operation 'Minimum_2/y' type=Const>, <tf.Operation 'Minimum_2' type=Minimum>, <tf.Operation 'Reshape_2/shape' type=Const>, <tf.Operation 'Reshape_2' type=Reshape>, <tf.Operation 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel' type=Const>, <tf.Operation 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel/read' type=Identity>, <tf.Operation 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias' type=Const>, <tf.Operation 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias/read' type=Identity>, <tf.Operation 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/zeros/shape_as_tensor' type=Const>, <tf.Operation 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/zeros/Const' type=Const>, <tf.Operation 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/zeros' type=Fill>, <tf.Operation 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/Const' type=Const>, <tf.Operation 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/Max' type=Max>, <tf.Operation 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/Cast' type=Cast>, <tf.Operation 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/BlockLSTM' type=BlockLSTM>, <tf.Operation 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/SequenceMask/Const' type=Const>, <tf.Operation 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/SequenceMask/Const_1' type=Const>, <tf.Operation 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/SequenceMask/Const_2' type=Const>, <tf.Operation 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/SequenceMask/Range' type=Range>, <tf.Operation 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/SequenceMask/ExpandDims/dim' type=Const>, <tf.Operation 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/SequenceMask/ExpandDims' type=ExpandDims>, <tf.Operation 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/SequenceMask/Cast' type=Cast>, <tf.Operation 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/SequenceMask/Less' type=Less>, <tf.Operation 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/SequenceMask/Cast_1' type=Cast>, <tf.Operation 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/transpose/perm' type=Const>, <tf.Operation 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/transpose' type=Transpose>, <tf.Operation 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/ExpandDims/dim' type=Const>, <tf.Operation 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/ExpandDims' type=ExpandDims>, <tf.Operation 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/Tile/multiples' type=Const>, <tf.Operation 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/Tile' type=Tile>, <tf.Operation 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/mul' type=Mul>, <tf.Operation 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/ExpandDims_1/dim' type=Const>, <tf.Operation 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/ExpandDims_1' type=ExpandDims>, <tf.Operation 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/concat/axis' type=Const>, <tf.Operation 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/concat' type=ConcatV2>, <tf.Operation 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/ExpandDims_2/dim' type=Const>, <tf.Operation 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/ExpandDims_2' type=ExpandDims>, <tf.Operation 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/concat_1/axis' type=Const>, <tf.Operation 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/concat_1' type=ConcatV2>, <tf.Operation 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/range/start' type=Const>, <tf.Operation 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/range/limit' type=Const>, <tf.Operation 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/range/delta' type=Const>, <tf.Operation 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/range' type=Range>, <tf.Operation 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/stack' type=Pack>, <tf.Operation 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/GatherNd' type=GatherNd>, <tf.Operation 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/range_1/start' type=Const>, <tf.Operation 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/range_1/limit' type=Const>, <tf.Operation 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/range_1/delta' type=Const>, <tf.Operation 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/range_1' type=Range>, <tf.Operation 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/stack_1' type=Pack>, <tf.Operation 'cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/GatherNd_1' type=GatherNd>, <tf.Operation 'Reshape_3/shape' type=Const>, <tf.Operation 'Reshape_3' type=Reshape>, <tf.Operation 'layer_5/bias' type=Const>, <tf.Operation 'layer_5/bias/read' type=Identity>, <tf.Operation 'layer_5/weights' type=Const>, <tf.Operation 'layer_5/weights/read' type=Identity>, <tf.Operation 'MatMul_3' type=MatMul>, <tf.Operation 'BiasAdd_3' type=BiasAdd>, <tf.Operation 'Relu_3' type=Relu>, <tf.Operation 'Minimum_3/y' type=Const>, <tf.Operation 'Minimum_3' type=Minimum>, <tf.Operation 'layer_6/bias' type=Const>, <tf.Operation 'layer_6/bias/read' type=Identity>, <tf.Operation 'layer_6/weights' type=Const>, <tf.Operation 'layer_6/weights/read' type=Identity>, <tf.Operation 'MatMul_4' type=MatMul>, <tf.Operation 'BiasAdd_4' type=BiasAdd>, <tf.Operation 'raw_logits/shape' type=Const>, <tf.Operation 'raw_logits' type=Reshape>, <tf.Operation 'logits' type=Softmax>, <tf.Operation 'new_state_c' type=Identity>, <tf.Operation 'new_state_h' type=Identity>, <tf.Operation 'metadata_version' type=Const>, <tf.Operation 'metadata_sample_rate' type=Const>, <tf.Operation 'metadata_feature_win_len' type=Const>, <tf.Operation 'metadata_feature_win_step' type=Const>, <tf.Operation 'metadata_alphabet' type=Const>, <tf.Operation 'input_1' type=Placeholder>, <tf.Operation 'reshape/Shape' type=Shape>, <tf.Operation 'reshape/strided_slice/stack' type=Const>, <tf.Operation 'reshape/strided_slice/stack_1' type=Const>, <tf.Operation 'reshape/strided_slice/stack_2' type=Const>, <tf.Operation 'reshape/strided_slice' type=StridedSlice>, <tf.Operation 'reshape/Reshape/shape/1' type=Const>, <tf.Operation 'reshape/Reshape/shape/2' type=Const>, <tf.Operation 'reshape/Reshape/shape' type=Pack>, <tf.Operation 'reshape/Reshape' type=Reshape>, <tf.Operation 'tt_dense_1/matrix/core_0' type=Const>, <tf.Operation 'tt_dense_1/matrix/core_0/read' type=Identity>, <tf.Operation 'tt_dense_1/matrix/core_1' type=Const>, <tf.Operation 'tt_dense_1/matrix/core_1/read' type=Identity>, <tf.Operation 'tt_dense_1/matrix/core_2' type=Const>, <tf.Operation 'tt_dense_1/matrix/core_2/read' type=Identity>, <tf.Operation 'tt_dense_1/matrix/core_3' type=Const>, <tf.Operation 'tt_dense_1/matrix/core_3/read' type=Identity>, <tf.Operation 'tt_dense_1/bias' type=Const>, <tf.Operation 'tt_dense_1/bias/read' type=Identity>, <tf.Operation 'keras_dense/t3f_matmul/transpose/perm' type=Const>, <tf.Operation 'keras_dense/t3f_matmul/transpose' type=Transpose>, <tf.Operation 'keras_dense/t3f_matmul/t3f_transpose/transpose/perm' type=Const>, <tf.Operation 'keras_dense/t3f_matmul/t3f_transpose/transpose' type=Transpose>, <tf.Operation 'keras_dense/t3f_matmul/t3f_transpose/transpose_1/perm' type=Const>, <tf.Operation 'keras_dense/t3f_matmul/t3f_transpose/transpose_1' type=Transpose>, <tf.Operation 'keras_dense/t3f_matmul/t3f_transpose/transpose_2/perm' type=Const>, <tf.Operation 'keras_dense/t3f_matmul/t3f_transpose/transpose_2' type=Transpose>, <tf.Operation 'keras_dense/t3f_matmul/t3f_transpose/transpose_3/perm' type=Const>, <tf.Operation 'keras_dense/t3f_matmul/t3f_transpose/transpose_3' type=Transpose>, <tf.Operation 'keras_dense/t3f_matmul/Shape' type=Shape>, <tf.Operation 'keras_dense/t3f_matmul/transpose_1/perm' type=Const>, <tf.Operation 'keras_dense/t3f_matmul/transpose_1' type=Transpose>, <tf.Operation 'keras_dense/t3f_matmul/Reshape/shape' type=Const>, <tf.Operation 'keras_dense/t3f_matmul/Reshape' type=Reshape>, <tf.Operation 'keras_dense/t3f_matmul/einsum/transpose/perm' type=Const>, <tf.Operation 'keras_dense/t3f_matmul/einsum/transpose' type=Transpose>, <tf.Operation 'keras_dense/t3f_matmul/einsum/transpose_1/perm' type=Const>, <tf.Operation 'keras_dense/t3f_matmul/einsum/transpose_1' type=Transpose>, <tf.Operation 'keras_dense/t3f_matmul/einsum/Reshape/shape' type=Const>, <tf.Operation 'keras_dense/t3f_matmul/einsum/Reshape' type=Reshape>, <tf.Operation 'keras_dense/t3f_matmul/einsum/Shape' type=Shape>, <tf.Operation 'keras_dense/t3f_matmul/einsum/strided_slice/stack' type=Const>, <tf.Operation 'keras_dense/t3f_matmul/einsum/strided_slice/stack_1' type=Const>, <tf.Operation 'keras_dense/t3f_matmul/einsum/strided_slice/stack_2' type=Const>, <tf.Operation 'keras_dense/t3f_matmul/einsum/strided_slice' type=StridedSlice>, <tf.Operation 'keras_dense/t3f_matmul/einsum/mul/x' type=Const>, <tf.Operation 'keras_dense/t3f_matmul/einsum/mul' type=Mul>, <tf.Operation 'keras_dense/t3f_matmul/einsum/Reshape_1/shape/0' type=Const>, <tf.Operation 'keras_dense/t3f_matmul/einsum/Reshape_1/shape' type=Pack>, <tf.Operation 'keras_dense/t3f_matmul/einsum/Reshape_1' type=Reshape>, <tf.Operation 'keras_dense/t3f_matmul/einsum/MatMul' type=MatMul>, <tf.Operation 'keras_dense/t3f_matmul/einsum/Reshape_2/shape/0' type=Const>, <tf.Operation 'keras_dense/t3f_matmul/einsum/Reshape_2/shape/1' type=Const>, <tf.Operation 'keras_dense/t3f_matmul/einsum/Reshape_2/shape' type=Pack>, <tf.Operation 'keras_dense/t3f_matmul/einsum/Reshape_2' type=Reshape>, <tf.Operation 'keras_dense/t3f_matmul/einsum/transpose_2/perm' type=Const>, <tf.Operation 'keras_dense/t3f_matmul/einsum/transpose_2' type=Transpose>, <tf.Operation 'keras_dense/t3f_matmul/Reshape_1/shape' type=Const>, <tf.Operation 'keras_dense/t3f_matmul/Reshape_1' type=Reshape>, <tf.Operation 'keras_dense/t3f_matmul/einsum_1/transpose/perm' type=Const>, <tf.Operation 'keras_dense/t3f_matmul/einsum_1/transpose' type=Transpose>, <tf.Operation 'keras_dense/t3f_matmul/einsum_1/transpose_1/perm' type=Const>, <tf.Operation 'keras_dense/t3f_matmul/einsum_1/transpose_1' type=Transpose>, <tf.Operation 'keras_dense/t3f_matmul/einsum_1/Reshape/shape' type=Const>, <tf.Operation 'keras_dense/t3f_matmul/einsum_1/Reshape' type=Reshape>, <tf.Operation 'keras_dense/t3f_matmul/einsum_1/Shape' type=Shape>, <tf.Operation 'keras_dense/t3f_matmul/einsum_1/strided_slice/stack' type=Const>, <tf.Operation 'keras_dense/t3f_matmul/einsum_1/strided_slice/stack_1' type=Const>, <tf.Operation 'keras_dense/t3f_matmul/einsum_1/strided_slice/stack_2' type=Const>, <tf.Operation 'keras_dense/t3f_matmul/einsum_1/strided_slice' type=StridedSlice>, <tf.Operation 'keras_dense/t3f_matmul/einsum_1/mul/x' type=Const>, <tf.Operation 'keras_dense/t3f_matmul/einsum_1/mul' type=Mul>, <tf.Operation 'keras_dense/t3f_matmul/einsum_1/Reshape_1/shape/0' type=Const>, <tf.Operation 'keras_dense/t3f_matmul/einsum_1/Reshape_1/shape' type=Pack>, <tf.Operation 'keras_dense/t3f_matmul/einsum_1/Reshape_1' type=Reshape>, <tf.Operation 'keras_dense/t3f_matmul/einsum_1/MatMul' type=MatMul>, <tf.Operation 'keras_dense/t3f_matmul/einsum_1/Reshape_2/shape/0' type=Const>, <tf.Operation 'keras_dense/t3f_matmul/einsum_1/Reshape_2/shape/1' type=Const>, <tf.Operation 'keras_dense/t3f_matmul/einsum_1/Reshape_2/shape' type=Pack>, <tf.Operation 'keras_dense/t3f_matmul/einsum_1/Reshape_2' type=Reshape>, <tf.Operation 'keras_dense/t3f_matmul/einsum_1/transpose_2/perm' type=Const>, <tf.Operation 'keras_dense/t3f_matmul/einsum_1/transpose_2' type=Transpose>, <tf.Operation 'keras_dense/t3f_matmul/Reshape_2/shape' type=Const>, <tf.Operation 'keras_dense/t3f_matmul/Reshape_2' type=Reshape>, <tf.Operation 'keras_dense/t3f_matmul/einsum_2/transpose/perm' type=Const>, <tf.Operation 'keras_dense/t3f_matmul/einsum_2/transpose' type=Transpose>, <tf.Operation 'keras_dense/t3f_matmul/einsum_2/transpose_1/perm' type=Const>, <tf.Operation 'keras_dense/t3f_matmul/einsum_2/transpose_1' type=Transpose>, <tf.Operation 'keras_dense/t3f_matmul/einsum_2/Reshape/shape' type=Const>, <tf.Operation 'keras_dense/t3f_matmul/einsum_2/Reshape' type=Reshape>, <tf.Operation 'keras_dense/t3f_matmul/einsum_2/Shape' type=Shape>, <tf.Operation 'keras_dense/t3f_matmul/einsum_2/strided_slice/stack' type=Const>, <tf.Operation 'keras_dense/t3f_matmul/einsum_2/strided_slice/stack_1' type=Const>, <tf.Operation 'keras_dense/t3f_matmul/einsum_2/strided_slice/stack_2' type=Const>, <tf.Operation 'keras_dense/t3f_matmul/einsum_2/strided_slice' type=StridedSlice>, <tf.Operation 'keras_dense/t3f_matmul/einsum_2/mul/x' type=Const>, <tf.Operation 'keras_dense/t3f_matmul/einsum_2/mul' type=Mul>, <tf.Operation 'keras_dense/t3f_matmul/einsum_2/Reshape_1/shape/0' type=Const>, <tf.Operation 'keras_dense/t3f_matmul/einsum_2/Reshape_1/shape' type=Pack>, <tf.Operation 'keras_dense/t3f_matmul/einsum_2/Reshape_1' type=Reshape>, <tf.Operation 'keras_dense/t3f_matmul/einsum_2/MatMul' type=MatMul>, <tf.Operation 'keras_dense/t3f_matmul/einsum_2/Reshape_2/shape/0' type=Const>, <tf.Operation 'keras_dense/t3f_matmul/einsum_2/Reshape_2/shape/1' type=Const>, <tf.Operation 'keras_dense/t3f_matmul/einsum_2/Reshape_2/shape' type=Pack>, <tf.Operation 'keras_dense/t3f_matmul/einsum_2/Reshape_2' type=Reshape>, <tf.Operation 'keras_dense/t3f_matmul/einsum_2/transpose_2/perm' type=Const>, <tf.Operation 'keras_dense/t3f_matmul/einsum_2/transpose_2' type=Transpose>, <tf.Operation 'keras_dense/t3f_matmul/Reshape_3/shape' type=Const>, <tf.Operation 'keras_dense/t3f_matmul/Reshape_3' type=Reshape>, <tf.Operation 'keras_dense/t3f_matmul/einsum_3/transpose/perm' type=Const>, <tf.Operation 'keras_dense/t3f_matmul/einsum_3/transpose' type=Transpose>, <tf.Operation 'keras_dense/t3f_matmul/einsum_3/transpose_1/perm' type=Const>, <tf.Operation 'keras_dense/t3f_matmul/einsum_3/transpose_1' type=Transpose>, <tf.Operation 'keras_dense/t3f_matmul/einsum_3/Reshape/shape' type=Const>, <tf.Operation 'keras_dense/t3f_matmul/einsum_3/Reshape' type=Reshape>, <tf.Operation 'keras_dense/t3f_matmul/einsum_3/Shape' type=Shape>, <tf.Operation 'keras_dense/t3f_matmul/einsum_3/strided_slice/stack' type=Const>, <tf.Operation 'keras_dense/t3f_matmul/einsum_3/strided_slice/stack_1' type=Const>, <tf.Operation 'keras_dense/t3f_matmul/einsum_3/strided_slice/stack_2' type=Const>, <tf.Operation 'keras_dense/t3f_matmul/einsum_3/strided_slice' type=StridedSlice>, <tf.Operation 'keras_dense/t3f_matmul/einsum_3/mul/x' type=Const>, <tf.Operation 'keras_dense/t3f_matmul/einsum_3/mul' type=Mul>, <tf.Operation 'keras_dense/t3f_matmul/einsum_3/Reshape_1/shape/0' type=Const>, <tf.Operation 'keras_dense/t3f_matmul/einsum_3/Reshape_1/shape' type=Pack>, <tf.Operation 'keras_dense/t3f_matmul/einsum_3/Reshape_1' type=Reshape>, <tf.Operation 'keras_dense/t3f_matmul/einsum_3/MatMul' type=MatMul>, <tf.Operation 'keras_dense/t3f_matmul/einsum_3/Reshape_2/shape/0' type=Const>, <tf.Operation 'keras_dense/t3f_matmul/einsum_3/Reshape_2/shape/1' type=Const>, <tf.Operation 'keras_dense/t3f_matmul/einsum_3/Reshape_2/shape' type=Pack>, <tf.Operation 'keras_dense/t3f_matmul/einsum_3/Reshape_2' type=Reshape>, <tf.Operation 'keras_dense/t3f_matmul/einsum_3/transpose_2/perm' type=Const>, <tf.Operation 'keras_dense/t3f_matmul/einsum_3/transpose_2' type=Transpose>, <tf.Operation 'keras_dense/t3f_matmul/strided_slice/stack' type=Const>, <tf.Operation 'keras_dense/t3f_matmul/strided_slice/stack_1' type=Const>, <tf.Operation 'keras_dense/t3f_matmul/strided_slice/stack_2' type=Const>, <tf.Operation 'keras_dense/t3f_matmul/strided_slice' type=StridedSlice>, <tf.Operation 'keras_dense/t3f_matmul/Reshape_4/shape/0' type=Const>, <tf.Operation 'keras_dense/t3f_matmul/Reshape_4/shape' type=Pack>, <tf.Operation 'keras_dense/t3f_matmul/Reshape_4' type=Reshape>, <tf.Operation 'keras_dense/t3f_matmul/transpose_2/perm' type=Const>, <tf.Operation 'keras_dense/t3f_matmul/transpose_2' type=Transpose>, <tf.Operation 'keras_dense/add' type=AddV2>, <tf.Operation 'keras_dense/activation/Relu' type=Relu>, <tf.Operation 'geph__Minimum_0' type=Placeholder>, <tf.Operation 'layer_2/weights/geph__read_0' type=Placeholder>, <tf.Operation 'geph__MatMul_1_0' type=Placeholder>, <tf.Operation 'geph__input_1_0' type=Placeholder>]\n",
      "name: \"input_samples\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_FLOAT\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "      dim {\n",
      "        size: 512\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gr_new = replace_layer_with_t3f(gr,wts,\"layer_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aW5Zeqj5wgiJ"
   },
   "outputs": [],
   "source": [
    "def freeze_session(session, keep_var_names=None, output_names=None, clear_devices=True):\n",
    "    \"\"\"\n",
    "    Freezes the state of a session into a pruned computation graph.\n",
    "\n",
    "    Creates a new computation graph where variable nodes are replaced by\n",
    "    constants taking their current value in the session. The new graph will be\n",
    "    pruned so subgraphs that are not necessary to compute the requested\n",
    "    outputs are removed.\n",
    "    @param session The TensorFlow session to be frozen.\n",
    "    @param keep_var_names A list of variable names that should not be frozen,\n",
    "                          or None to freeze all the variables in the graph.\n",
    "    @param output_names Names of the relevant graph outputs.\n",
    "    @param clear_devices Remove the device directives from the graph for better portability.\n",
    "    @return The frozen graph definition.\n",
    "    \"\"\"\n",
    "    graph = session.graph\n",
    "    with graph.as_default():\n",
    "        freeze_var_names = list(set(v.op.name for v in tf.global_variables()).difference(keep_var_names or []))\n",
    "        output_names = output_names or []\n",
    "        output_names += [v.op.name for v in tf.global_variables()]\n",
    "        input_graph_def = graph.as_graph_def()\n",
    "        if clear_devices:\n",
    "            for node in input_graph_def.node:\n",
    "                node.device = \"\"\n",
    "        frozen_graph = tf.graph_util.convert_variables_to_constants(\n",
    "            session, input_graph_def, output_names, freeze_var_names)\n",
    "        return frozen_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yofz5p3PzpU_"
   },
   "outputs": [],
   "source": [
    "def load_graph(frozen_graph_filename):\n",
    "    with tf.io.gfile.GFile(frozen_graph_filename, \"rb\") as f:\n",
    "        graph_def = tf.compat.v1.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.import_graph_def(graph_def)\n",
    "    return graph\n",
    "\n",
    "def analyze_inputs_outputs(graph):\n",
    "    ops = graph.get_operations()\n",
    "    outputs_set = set(ops)\n",
    "    inputs = []\n",
    "    for op in ops:\n",
    "        if len(op.inputs) == 0 and op.type != 'Const':\n",
    "            inputs.append(op)\n",
    "        else:\n",
    "            for input_tensor in op.inputs:\n",
    "                if input_tensor.op in outputs_set:\n",
    "                    outputs_set.remove(input_tensor.op)\n",
    "    outputs = list(outputs_set)\n",
    "    return (inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AnM2XCvT5cd5"
   },
   "outputs": [],
   "source": [
    "i,o = analyze_inputs_outputs(gr_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "JjRZ11wt956e",
    "outputId": "88f65619-16e2-49a1-bb43-d62ebcbce765"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'input_samples' type=Placeholder>,\n",
       " <tf.Operation 'input_node' type=Placeholder>,\n",
       " <tf.Operation 'input_lengths' type=Placeholder>,\n",
       " <tf.Operation 'previous_state_c' type=Placeholder>,\n",
       " <tf.Operation 'previous_state_h' type=Placeholder>,\n",
       " <tf.Operation 'input_1' type=Placeholder>,\n",
       " <tf.Operation 'geph__Minimum_0' type=Placeholder>,\n",
       " <tf.Operation 'layer_2/weights/geph__read_0' type=Placeholder>,\n",
       " <tf.Operation 'geph__MatMul_1_0' type=Placeholder>,\n",
       " <tf.Operation 'geph__input_1_0' type=Placeholder>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "OC83VhCqCH9T",
    "outputId": "187cde77-8644-4b54-fdf2-d62b64f46e97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_samples\n",
      "dim {\n",
      "  size: 512\n",
      "}\n",
      "\n",
      "-------\n",
      "input_node\n",
      "dim {\n",
      "  size: 1\n",
      "}\n",
      "dim {\n",
      "  size: 16\n",
      "}\n",
      "dim {\n",
      "  size: 19\n",
      "}\n",
      "dim {\n",
      "  size: 26\n",
      "}\n",
      "\n",
      "-------\n",
      "input_lengths\n",
      "dim {\n",
      "  size: 1\n",
      "}\n",
      "\n",
      "-------\n",
      "previous_state_c\n",
      "dim {\n",
      "  size: 1\n",
      "}\n",
      "dim {\n",
      "  size: 2048\n",
      "}\n",
      "\n",
      "-------\n",
      "previous_state_h\n",
      "dim {\n",
      "  size: 1\n",
      "}\n",
      "dim {\n",
      "  size: 2048\n",
      "}\n",
      "\n",
      "-------\n",
      "input_1\n",
      "dim {\n",
      "  size: -1\n",
      "}\n",
      "dim {\n",
      "  size: 2048\n",
      "}\n",
      "\n",
      "-------\n",
      "geph__Minimum_0\n",
      "unknown_rank: true\n",
      "\n",
      "-------\n",
      "layer_2/weights/geph__read_0\n",
      "unknown_rank: true\n",
      "\n",
      "-------\n",
      "geph__MatMul_1_0\n",
      "dim {\n",
      "  size: 16\n",
      "}\n",
      "dim {\n",
      "  size: 2048\n",
      "}\n",
      "\n",
      "-------\n",
      "geph__input_1_0\n",
      "dim {\n",
      "  size: -1\n",
      "}\n",
      "dim {\n",
      "  size: 2048\n",
      "}\n",
      "\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "for inp in i:\n",
    "  print(inp.name)\n",
    "  print(inp.get_attr(\"shape\"))\n",
    "  print(\"-------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "tAokVJpCCn10",
    "outputId": "d593e616-4fa3-43ad-a18f-23a4bb8f18df"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'metadata_feature_win_len' type=Const>,\n",
       " <tf.Operation 'layer_2/weights/read' type=Identity>,\n",
       " <tf.Operation 'MatMul_1' type=MatMul>,\n",
       " <tf.Operation 'metadata_feature_win_step' type=Const>,\n",
       " <tf.Operation 'Relu_1' type=Relu>,\n",
       " <tf.Operation 'metadata_alphabet' type=Const>,\n",
       " <tf.Operation 'metadata_version' type=Const>,\n",
       " <tf.Operation 'mfccs' type=Identity>,\n",
       " <tf.Operation 'logits' type=Softmax>,\n",
       " <tf.Operation 'input_1' type=Placeholder>,\n",
       " <tf.Operation 'metadata_sample_rate' type=Const>,\n",
       " <tf.Operation 'new_state_c' type=Identity>,\n",
       " <tf.Operation 'new_state_h' type=Identity>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nWekXQCqI47Y"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MsPJX0I6BQPb"
   },
   "outputs": [],
   "source": [
    "i1 = gr.get_tensor_by_name('input_samples:0')\n",
    "i2 = gr.get_tensor_by_name('input_node:0')\n",
    "i3 = gr.get_tensor_by_name('input_lengths:0')\n",
    "i4 = gr.get_tensor_by_name('previous_state_c:0')\n",
    "i5 = gr.get_tensor_by_name('previous_state_h:0')\n",
    "i6 = gr.get_tensor_by_name(\"input_1:0\")\n",
    "i7 = gr.get_tensor_by_name('geph__input_1_0:0')\n",
    "\n",
    "t1 = np.ones(512,dtype=float) * 0.001\n",
    "t2 = np.ones((1,16,19,26),dtype=float) * 0.021\n",
    "t3 = [3]#np.array([3],dtype=np.int32)\n",
    "t4 = np.zeros((1,2048),dtype=float) * 0.001\n",
    "t5 = np.zeros((1,2048),dtype=float) * 0.001\n",
    "t6 = np.zeros((1,2048),dtype=float)\n",
    "t7 = np.zeros((1,2048),dtype=float)\n",
    "\n",
    "out = gr.get_operation_by_name('logits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "33t1rPOXA9Kk"
   },
   "outputs": [],
   "source": [
    "with tf.Session(graph=gr) as sess:\n",
    " # sess.run(out,)\n",
    "  x = gr.get_tensor_by_name(\"logits:0\")\n",
    "  res = x.eval(feed_dict={i1:t1,i2:t2,i3:t3,i4:t4,i5:t5,i6:t6,i7:t7})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "aAwpdHLU_jfr",
    "outputId": "2bc43d68-a094-4fbc-d9d0-6fb6bc1e1dd3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 1, 29)"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "frEyPpwl91i7"
   },
   "outputs": [],
   "source": [
    "\n",
    "with tf.Session() as sess:\n",
    "  with tf.gfile.GFile(\"x.pb\", \"wb\") as f:\n",
    "      f.write(gr.as_graph_def().SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TeGOao_J-dS4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "T3F_with_deep_speech",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
